{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.4950\n",
      "Epoch [200/1000], Loss: 0.3600\n",
      "Epoch [300/1000], Loss: 0.2687\n",
      "Epoch [400/1000], Loss: 0.2081\n",
      "Epoch [500/1000], Loss: 0.1684\n",
      "Epoch [600/1000], Loss: 0.1418\n",
      "Epoch [700/1000], Loss: 0.1229\n",
      "Epoch [800/1000], Loss: 0.1091\n",
      "Epoch [900/1000], Loss: 0.0985\n",
      "Epoch [1000/1000], Loss: 0.0901\n",
      "\n",
      "預測結果: tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# 創建一個簡單的神經網絡\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 生成示例數據\n",
    "X = torch.randn(100, 2)\n",
    "y = torch.zeros(100)\n",
    "y[X[:, 0] + X[:, 1] > 0] = 1\n",
    "y = y.long()\n",
    "\n",
    "# 初始化模型和優化器\n",
    "model = SimpleNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 訓練模型\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 測試模型\n",
    "with torch.no_grad():\n",
    "    test_X = torch.randn(10, 2)\n",
    "    predictions = model(test_X)\n",
    "    _, predicted = torch.max(predictions.data, 1)\n",
    "    print('\\n預測結果:', predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 0.1281\n",
      "Epoch [1/5], Step [200/938], Loss: 0.1591\n",
      "Epoch [1/5], Step [300/938], Loss: 0.0385\n",
      "Epoch [1/5], Step [400/938], Loss: 0.0050\n",
      "Epoch [1/5], Step [500/938], Loss: 0.0260\n",
      "Epoch [1/5], Step [600/938], Loss: 0.0405\n",
      "Epoch [1/5], Step [700/938], Loss: 0.0578\n",
      "Epoch [1/5], Step [800/938], Loss: 0.0955\n",
      "Epoch [1/5], Step [900/938], Loss: 0.0437\n",
      "Epoch [2/5], Step [100/938], Loss: 0.0099\n",
      "Epoch [2/5], Step [200/938], Loss: 0.0018\n",
      "Epoch [2/5], Step [300/938], Loss: 0.1365\n",
      "Epoch [2/5], Step [400/938], Loss: 0.0219\n",
      "Epoch [2/5], Step [500/938], Loss: 0.0642\n",
      "Epoch [2/5], Step [600/938], Loss: 0.0219\n",
      "Epoch [2/5], Step [700/938], Loss: 0.0121\n",
      "Epoch [2/5], Step [800/938], Loss: 0.0038\n",
      "Epoch [2/5], Step [900/938], Loss: 0.0217\n",
      "Epoch [3/5], Step [100/938], Loss: 0.0276\n",
      "Epoch [3/5], Step [200/938], Loss: 0.0144\n",
      "Epoch [3/5], Step [300/938], Loss: 0.0166\n",
      "Epoch [3/5], Step [400/938], Loss: 0.0069\n",
      "Epoch [3/5], Step [500/938], Loss: 0.0170\n",
      "Epoch [3/5], Step [600/938], Loss: 0.2308\n",
      "Epoch [3/5], Step [700/938], Loss: 0.0146\n",
      "Epoch [3/5], Step [800/938], Loss: 0.0052\n",
      "Epoch [3/5], Step [900/938], Loss: 0.1420\n",
      "Epoch [4/5], Step [100/938], Loss: 0.1028\n",
      "Epoch [4/5], Step [200/938], Loss: 0.0085\n",
      "Epoch [4/5], Step [300/938], Loss: 0.0081\n",
      "Epoch [4/5], Step [400/938], Loss: 0.0118\n",
      "Epoch [4/5], Step [500/938], Loss: 0.0048\n",
      "Epoch [4/5], Step [600/938], Loss: 0.0091\n",
      "Epoch [4/5], Step [700/938], Loss: 0.0335\n",
      "Epoch [4/5], Step [800/938], Loss: 0.0097\n",
      "Epoch [4/5], Step [900/938], Loss: 0.0161\n",
      "Epoch [5/5], Step [100/938], Loss: 0.0150\n",
      "Epoch [5/5], Step [200/938], Loss: 0.0103\n",
      "Epoch [5/5], Step [300/938], Loss: 0.0021\n",
      "Epoch [5/5], Step [400/938], Loss: 0.0041\n",
      "Epoch [5/5], Step [500/938], Loss: 0.0034\n",
      "Epoch [5/5], Step [600/938], Loss: 0.0176\n",
      "Epoch [5/5], Step [700/938], Loss: 0.0107\n",
      "Epoch [5/5], Step [800/938], Loss: 0.0004\n",
      "Epoch [5/5], Step [900/938], Loss: 0.0018\n",
      "測試準確率: 99.17%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 設定設備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 載入MNIST數據集\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=True, \n",
    "                                          transform=transform,\n",
    "                                          download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                         train=False, \n",
    "                                         transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 定義CNN模型\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)  # 輸入 28x28 -> 26x26\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)  # 13x13 -> 11x11\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)  # 修正輸入維度\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # 26x26 -> 13x13\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # 11x11 -> 5x5\n",
    "        x = x.view(-1, 64 * 5 * 5)  # 攤平特徵圖\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 訓練模型\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 評估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'測試準確率: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用設備: mps\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 1/30\n",
      "Batch: 20/391, Loss: 2.2801, Acc: 13.36%\n",
      "Batch: 40/391, Loss: 2.0844, Acc: 15.51%\n",
      "Batch: 60/391, Loss: 2.0683, Acc: 17.83%\n",
      "Batch: 80/391, Loss: 2.0379, Acc: 19.51%\n",
      "Batch: 100/391, Loss: 2.0787, Acc: 20.65%\n",
      "Batch: 120/391, Loss: 1.9865, Acc: 21.59%\n",
      "Batch: 140/391, Loss: 1.9857, Acc: 22.33%\n",
      "Batch: 160/391, Loss: 1.9353, Acc: 23.07%\n",
      "Batch: 180/391, Loss: 1.7493, Acc: 24.18%\n",
      "Batch: 200/391, Loss: 1.8927, Acc: 25.00%\n",
      "Batch: 220/391, Loss: 1.8387, Acc: 25.66%\n",
      "Batch: 240/391, Loss: 1.6529, Acc: 26.50%\n",
      "Batch: 260/391, Loss: 1.9347, Acc: 27.06%\n",
      "Batch: 280/391, Loss: 1.6909, Acc: 27.61%\n",
      "Batch: 300/391, Loss: 1.6989, Acc: 28.15%\n",
      "Batch: 320/391, Loss: 1.7887, Acc: 28.66%\n",
      "Batch: 340/391, Loss: 1.6349, Acc: 29.17%\n",
      "Batch: 360/391, Loss: 1.5916, Acc: 29.70%\n",
      "Batch: 380/391, Loss: 1.6464, Acc: 30.18%\n",
      "Epoch Time: 93.25s\n",
      "Train Loss: 1.8949 | Train Acc: 30.44%\n",
      "Test Loss: 1.4408 | Test Acc: 45.94%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 2/30\n",
      "Batch: 20/391, Loss: 1.5297, Acc: 40.16%\n",
      "Batch: 40/391, Loss: 1.6600, Acc: 40.62%\n",
      "Batch: 60/391, Loss: 1.5909, Acc: 40.78%\n",
      "Batch: 80/391, Loss: 1.6181, Acc: 41.06%\n",
      "Batch: 100/391, Loss: 1.6152, Acc: 41.34%\n",
      "Batch: 120/391, Loss: 1.7167, Acc: 41.67%\n",
      "Batch: 140/391, Loss: 1.6003, Acc: 41.86%\n",
      "Batch: 160/391, Loss: 1.5000, Acc: 42.04%\n",
      "Batch: 180/391, Loss: 1.5303, Acc: 42.14%\n",
      "Batch: 200/391, Loss: 1.4881, Acc: 42.38%\n",
      "Batch: 220/391, Loss: 1.4391, Acc: 42.73%\n",
      "Batch: 240/391, Loss: 1.4179, Acc: 42.96%\n",
      "Batch: 260/391, Loss: 1.4399, Acc: 43.35%\n",
      "Batch: 280/391, Loss: 1.4131, Acc: 43.60%\n",
      "Batch: 300/391, Loss: 1.4958, Acc: 43.80%\n",
      "Batch: 320/391, Loss: 1.3504, Acc: 43.97%\n",
      "Batch: 340/391, Loss: 1.5883, Acc: 44.15%\n",
      "Batch: 360/391, Loss: 1.4607, Acc: 44.29%\n",
      "Batch: 380/391, Loss: 1.4279, Acc: 44.55%\n",
      "Epoch Time: 80.09s\n",
      "Train Loss: 1.5135 | Train Acc: 44.71%\n",
      "Test Loss: 1.2157 | Test Acc: 56.13%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 3/30\n",
      "Batch: 20/391, Loss: 1.3335, Acc: 47.89%\n",
      "Batch: 40/391, Loss: 1.3950, Acc: 47.95%\n",
      "Batch: 60/391, Loss: 1.3976, Acc: 48.65%\n",
      "Batch: 80/391, Loss: 1.5470, Acc: 48.92%\n",
      "Batch: 100/391, Loss: 1.4156, Acc: 49.38%\n",
      "Batch: 120/391, Loss: 1.3200, Acc: 49.38%\n",
      "Batch: 140/391, Loss: 1.2818, Acc: 49.70%\n",
      "Batch: 160/391, Loss: 1.4042, Acc: 49.67%\n",
      "Batch: 180/391, Loss: 1.4076, Acc: 49.94%\n",
      "Batch: 200/391, Loss: 1.3474, Acc: 50.15%\n",
      "Batch: 220/391, Loss: 1.4377, Acc: 50.45%\n",
      "Batch: 240/391, Loss: 1.1775, Acc: 50.53%\n",
      "Batch: 260/391, Loss: 1.4528, Acc: 50.75%\n",
      "Batch: 280/391, Loss: 1.2147, Acc: 50.86%\n",
      "Batch: 300/391, Loss: 1.2488, Acc: 51.04%\n",
      "Batch: 320/391, Loss: 1.1716, Acc: 51.23%\n",
      "Batch: 340/391, Loss: 1.2757, Acc: 51.39%\n",
      "Batch: 360/391, Loss: 1.3587, Acc: 51.49%\n",
      "Batch: 380/391, Loss: 1.2307, Acc: 51.66%\n",
      "Epoch Time: 79.85s\n",
      "Train Loss: 1.3416 | Train Acc: 51.71%\n",
      "Test Loss: 1.0667 | Test Acc: 61.10%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 4/30\n",
      "Batch: 20/391, Loss: 1.2917, Acc: 55.55%\n",
      "Batch: 40/391, Loss: 1.1375, Acc: 56.17%\n",
      "Batch: 60/391, Loss: 1.3829, Acc: 55.46%\n",
      "Batch: 80/391, Loss: 1.3524, Acc: 55.15%\n",
      "Batch: 100/391, Loss: 1.2438, Acc: 55.24%\n",
      "Batch: 120/391, Loss: 1.1787, Acc: 55.56%\n",
      "Batch: 140/391, Loss: 1.0875, Acc: 55.44%\n",
      "Batch: 160/391, Loss: 1.1475, Acc: 55.51%\n",
      "Batch: 180/391, Loss: 1.4152, Acc: 55.50%\n",
      "Batch: 200/391, Loss: 1.0393, Acc: 55.66%\n",
      "Batch: 220/391, Loss: 1.0503, Acc: 55.90%\n",
      "Batch: 240/391, Loss: 1.2903, Acc: 55.97%\n",
      "Batch: 260/391, Loss: 1.2002, Acc: 55.98%\n",
      "Batch: 280/391, Loss: 1.0564, Acc: 56.01%\n",
      "Batch: 300/391, Loss: 1.1188, Acc: 56.14%\n",
      "Batch: 320/391, Loss: 1.1432, Acc: 56.20%\n",
      "Batch: 340/391, Loss: 1.1066, Acc: 56.31%\n",
      "Batch: 360/391, Loss: 1.3085, Acc: 56.35%\n",
      "Batch: 380/391, Loss: 1.1787, Acc: 56.54%\n",
      "Epoch Time: 85.70s\n",
      "Train Loss: 1.2224 | Train Acc: 56.57%\n",
      "Test Loss: 0.9489 | Test Acc: 65.90%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 5/30\n",
      "Batch: 20/391, Loss: 1.0577, Acc: 57.73%\n",
      "Batch: 40/391, Loss: 1.0457, Acc: 57.71%\n",
      "Batch: 60/391, Loss: 1.2652, Acc: 58.18%\n",
      "Batch: 80/391, Loss: 1.0898, Acc: 58.43%\n",
      "Batch: 100/391, Loss: 1.1078, Acc: 58.71%\n",
      "Batch: 120/391, Loss: 1.1354, Acc: 58.98%\n",
      "Batch: 140/391, Loss: 1.2118, Acc: 59.14%\n",
      "Batch: 160/391, Loss: 1.1935, Acc: 59.28%\n",
      "Batch: 180/391, Loss: 1.1978, Acc: 59.15%\n",
      "Batch: 200/391, Loss: 1.2422, Acc: 59.34%\n",
      "Batch: 220/391, Loss: 1.0787, Acc: 59.45%\n",
      "Batch: 240/391, Loss: 1.0185, Acc: 59.57%\n",
      "Batch: 260/391, Loss: 1.2408, Acc: 59.74%\n",
      "Batch: 280/391, Loss: 1.1114, Acc: 59.86%\n",
      "Batch: 300/391, Loss: 1.2404, Acc: 59.94%\n",
      "Batch: 320/391, Loss: 0.9254, Acc: 60.10%\n",
      "Batch: 340/391, Loss: 1.2140, Acc: 60.22%\n",
      "Batch: 360/391, Loss: 1.0144, Acc: 60.35%\n",
      "Batch: 380/391, Loss: 1.1603, Acc: 60.44%\n",
      "Epoch Time: 84.57s\n",
      "Train Loss: 1.1208 | Train Acc: 60.44%\n",
      "Test Loss: 0.8826 | Test Acc: 68.75%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 6/30\n",
      "Batch: 20/391, Loss: 0.9529, Acc: 62.19%\n",
      "Batch: 40/391, Loss: 1.1524, Acc: 62.25%\n",
      "Batch: 60/391, Loss: 1.2179, Acc: 62.66%\n",
      "Batch: 80/391, Loss: 0.8528, Acc: 62.77%\n",
      "Batch: 100/391, Loss: 0.9932, Acc: 62.85%\n",
      "Batch: 120/391, Loss: 0.9281, Acc: 62.94%\n",
      "Batch: 140/391, Loss: 1.0876, Acc: 62.95%\n",
      "Batch: 160/391, Loss: 1.0047, Acc: 63.00%\n",
      "Batch: 180/391, Loss: 1.0736, Acc: 63.11%\n",
      "Batch: 200/391, Loss: 0.9460, Acc: 63.15%\n",
      "Batch: 220/391, Loss: 1.2764, Acc: 63.19%\n",
      "Batch: 240/391, Loss: 1.0723, Acc: 63.24%\n",
      "Batch: 260/391, Loss: 1.0684, Acc: 63.29%\n",
      "Batch: 280/391, Loss: 0.9263, Acc: 63.45%\n",
      "Batch: 300/391, Loss: 1.1940, Acc: 63.53%\n",
      "Batch: 320/391, Loss: 1.0031, Acc: 63.49%\n",
      "Batch: 340/391, Loss: 0.9197, Acc: 63.55%\n",
      "Batch: 360/391, Loss: 0.9959, Acc: 63.70%\n",
      "Batch: 380/391, Loss: 1.1786, Acc: 63.68%\n",
      "Epoch Time: 87.81s\n",
      "Train Loss: 1.0421 | Train Acc: 63.74%\n",
      "Test Loss: 0.7903 | Test Acc: 71.31%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 7/30\n",
      "Batch: 20/391, Loss: 0.9829, Acc: 64.61%\n",
      "Batch: 40/391, Loss: 1.1642, Acc: 64.08%\n",
      "Batch: 60/391, Loss: 1.0397, Acc: 64.61%\n",
      "Batch: 80/391, Loss: 1.1180, Acc: 64.65%\n",
      "Batch: 100/391, Loss: 0.8093, Acc: 64.62%\n",
      "Batch: 120/391, Loss: 1.0063, Acc: 64.59%\n",
      "Batch: 140/391, Loss: 1.1193, Acc: 64.68%\n",
      "Batch: 160/391, Loss: 0.9868, Acc: 64.86%\n",
      "Batch: 180/391, Loss: 0.8499, Acc: 65.16%\n",
      "Batch: 200/391, Loss: 0.9632, Acc: 65.24%\n",
      "Batch: 220/391, Loss: 0.8800, Acc: 65.38%\n",
      "Batch: 240/391, Loss: 0.9634, Acc: 65.49%\n",
      "Batch: 260/391, Loss: 1.0244, Acc: 65.57%\n",
      "Batch: 280/391, Loss: 0.8577, Acc: 65.59%\n",
      "Batch: 300/391, Loss: 0.9358, Acc: 65.57%\n",
      "Batch: 320/391, Loss: 1.0933, Acc: 65.65%\n",
      "Batch: 340/391, Loss: 0.9588, Acc: 65.72%\n",
      "Batch: 360/391, Loss: 0.8165, Acc: 65.77%\n",
      "Batch: 380/391, Loss: 0.8925, Acc: 65.92%\n",
      "Epoch Time: 87.72s\n",
      "Train Loss: 0.9740 | Train Acc: 65.98%\n",
      "Test Loss: 0.7163 | Test Acc: 74.56%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 8/30\n",
      "Batch: 20/391, Loss: 1.0047, Acc: 68.28%\n",
      "Batch: 40/391, Loss: 1.0222, Acc: 68.20%\n",
      "Batch: 60/391, Loss: 0.9902, Acc: 67.79%\n",
      "Batch: 80/391, Loss: 0.9031, Acc: 67.78%\n",
      "Batch: 100/391, Loss: 0.9380, Acc: 67.96%\n",
      "Batch: 120/391, Loss: 1.0173, Acc: 68.20%\n",
      "Batch: 140/391, Loss: 0.8579, Acc: 68.32%\n",
      "Batch: 160/391, Loss: 0.8621, Acc: 68.41%\n",
      "Batch: 180/391, Loss: 0.6292, Acc: 68.45%\n",
      "Batch: 200/391, Loss: 0.8206, Acc: 68.50%\n",
      "Batch: 220/391, Loss: 1.0348, Acc: 68.44%\n",
      "Batch: 240/391, Loss: 0.8692, Acc: 68.49%\n",
      "Batch: 260/391, Loss: 0.9624, Acc: 68.49%\n",
      "Batch: 280/391, Loss: 1.0110, Acc: 68.53%\n",
      "Batch: 300/391, Loss: 0.9205, Acc: 68.63%\n",
      "Batch: 320/391, Loss: 0.9009, Acc: 68.74%\n",
      "Batch: 340/391, Loss: 0.9201, Acc: 68.84%\n",
      "Batch: 360/391, Loss: 0.9628, Acc: 68.91%\n",
      "Batch: 380/391, Loss: 1.0475, Acc: 68.94%\n",
      "Epoch Time: 86.63s\n",
      "Train Loss: 0.9063 | Train Acc: 68.93%\n",
      "Test Loss: 0.6880 | Test Acc: 76.43%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 9/30\n",
      "Batch: 20/391, Loss: 0.7926, Acc: 69.30%\n",
      "Batch: 40/391, Loss: 0.9193, Acc: 69.36%\n",
      "Batch: 60/391, Loss: 0.8488, Acc: 69.61%\n",
      "Batch: 80/391, Loss: 1.1564, Acc: 69.97%\n",
      "Batch: 100/391, Loss: 0.8285, Acc: 69.86%\n",
      "Batch: 120/391, Loss: 0.9098, Acc: 69.90%\n",
      "Batch: 140/391, Loss: 0.8329, Acc: 70.01%\n",
      "Batch: 160/391, Loss: 0.8968, Acc: 70.08%\n",
      "Batch: 180/391, Loss: 0.8721, Acc: 70.21%\n",
      "Batch: 200/391, Loss: 0.8598, Acc: 70.42%\n",
      "Batch: 220/391, Loss: 0.9154, Acc: 70.33%\n",
      "Batch: 240/391, Loss: 0.9405, Acc: 70.52%\n",
      "Batch: 260/391, Loss: 0.9562, Acc: 70.45%\n",
      "Batch: 280/391, Loss: 0.8175, Acc: 70.60%\n",
      "Batch: 300/391, Loss: 0.8076, Acc: 70.68%\n",
      "Batch: 320/391, Loss: 0.7828, Acc: 70.74%\n",
      "Batch: 340/391, Loss: 0.8229, Acc: 70.73%\n",
      "Batch: 360/391, Loss: 0.8010, Acc: 70.74%\n",
      "Batch: 380/391, Loss: 1.0160, Acc: 70.79%\n",
      "Epoch Time: 87.62s\n",
      "Train Loss: 0.8595 | Train Acc: 70.79%\n",
      "Test Loss: 0.6356 | Test Acc: 78.01%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 10/30\n",
      "Batch: 20/391, Loss: 0.9635, Acc: 71.91%\n",
      "Batch: 40/391, Loss: 0.9405, Acc: 72.19%\n",
      "Batch: 60/391, Loss: 0.6384, Acc: 72.29%\n",
      "Batch: 80/391, Loss: 0.7765, Acc: 72.71%\n",
      "Batch: 100/391, Loss: 0.7546, Acc: 72.52%\n",
      "Batch: 120/391, Loss: 0.8190, Acc: 72.45%\n",
      "Batch: 140/391, Loss: 0.7917, Acc: 72.42%\n",
      "Batch: 160/391, Loss: 0.7564, Acc: 72.37%\n",
      "Batch: 180/391, Loss: 0.9001, Acc: 72.53%\n",
      "Batch: 200/391, Loss: 0.7535, Acc: 72.50%\n",
      "Batch: 220/391, Loss: 0.8933, Acc: 72.48%\n",
      "Batch: 240/391, Loss: 0.8925, Acc: 72.61%\n",
      "Batch: 260/391, Loss: 0.9533, Acc: 72.59%\n",
      "Batch: 280/391, Loss: 0.6606, Acc: 72.49%\n",
      "Batch: 300/391, Loss: 0.7702, Acc: 72.56%\n",
      "Batch: 320/391, Loss: 0.8473, Acc: 72.69%\n",
      "Batch: 340/391, Loss: 0.8881, Acc: 72.67%\n",
      "Batch: 360/391, Loss: 1.0081, Acc: 72.68%\n",
      "Batch: 380/391, Loss: 0.8251, Acc: 72.82%\n",
      "Epoch Time: 92.99s\n",
      "Train Loss: 0.8050 | Train Acc: 72.79%\n",
      "Test Loss: 0.5926 | Test Acc: 79.73%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 11/30\n",
      "Batch: 20/391, Loss: 0.7562, Acc: 73.63%\n",
      "Batch: 40/391, Loss: 0.9632, Acc: 73.20%\n",
      "Batch: 60/391, Loss: 0.7490, Acc: 73.55%\n",
      "Batch: 80/391, Loss: 0.8036, Acc: 73.51%\n",
      "Batch: 100/391, Loss: 0.7596, Acc: 73.66%\n",
      "Batch: 120/391, Loss: 0.9779, Acc: 73.70%\n",
      "Batch: 140/391, Loss: 0.8883, Acc: 73.68%\n",
      "Batch: 160/391, Loss: 0.8396, Acc: 73.88%\n",
      "Batch: 180/391, Loss: 0.4664, Acc: 74.01%\n",
      "Batch: 200/391, Loss: 0.7173, Acc: 74.10%\n",
      "Batch: 220/391, Loss: 0.7123, Acc: 74.09%\n",
      "Batch: 240/391, Loss: 0.8156, Acc: 74.01%\n",
      "Batch: 260/391, Loss: 0.7788, Acc: 74.03%\n",
      "Batch: 280/391, Loss: 0.8577, Acc: 74.06%\n",
      "Batch: 300/391, Loss: 0.7652, Acc: 74.02%\n",
      "Batch: 320/391, Loss: 0.8601, Acc: 74.05%\n",
      "Batch: 340/391, Loss: 0.8718, Acc: 74.08%\n",
      "Batch: 360/391, Loss: 0.8163, Acc: 74.18%\n",
      "Batch: 380/391, Loss: 0.9024, Acc: 74.25%\n",
      "Epoch Time: 90.77s\n",
      "Train Loss: 0.7702 | Train Acc: 74.21%\n",
      "Test Loss: 0.5667 | Test Acc: 80.72%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 12/30\n",
      "Batch: 20/391, Loss: 0.6520, Acc: 76.13%\n",
      "Batch: 40/391, Loss: 0.6451, Acc: 76.13%\n",
      "Batch: 60/391, Loss: 0.7441, Acc: 75.90%\n",
      "Batch: 80/391, Loss: 0.6831, Acc: 75.69%\n",
      "Batch: 100/391, Loss: 0.8157, Acc: 75.30%\n",
      "Batch: 120/391, Loss: 0.7632, Acc: 75.36%\n",
      "Batch: 140/391, Loss: 0.7563, Acc: 75.40%\n",
      "Batch: 160/391, Loss: 0.7000, Acc: 75.23%\n",
      "Batch: 180/391, Loss: 0.5777, Acc: 75.27%\n",
      "Batch: 200/391, Loss: 0.6951, Acc: 75.37%\n",
      "Batch: 220/391, Loss: 0.5466, Acc: 75.56%\n",
      "Batch: 240/391, Loss: 0.7835, Acc: 75.61%\n",
      "Batch: 260/391, Loss: 0.6572, Acc: 75.66%\n",
      "Batch: 280/391, Loss: 0.5945, Acc: 75.67%\n",
      "Batch: 300/391, Loss: 0.7230, Acc: 75.56%\n",
      "Batch: 320/391, Loss: 0.7314, Acc: 75.56%\n",
      "Batch: 340/391, Loss: 0.8891, Acc: 75.56%\n",
      "Batch: 360/391, Loss: 0.5723, Acc: 75.63%\n",
      "Batch: 380/391, Loss: 0.7494, Acc: 75.68%\n",
      "Epoch Time: 89.22s\n",
      "Train Loss: 0.7216 | Train Acc: 75.77%\n",
      "Test Loss: 0.5511 | Test Acc: 81.60%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 13/30\n",
      "Batch: 20/391, Loss: 0.7318, Acc: 78.32%\n",
      "Batch: 40/391, Loss: 0.5588, Acc: 78.09%\n",
      "Batch: 60/391, Loss: 0.5448, Acc: 77.45%\n",
      "Batch: 80/391, Loss: 0.7494, Acc: 77.03%\n",
      "Batch: 100/391, Loss: 0.7179, Acc: 76.95%\n",
      "Batch: 120/391, Loss: 0.7086, Acc: 76.80%\n",
      "Batch: 140/391, Loss: 0.6518, Acc: 76.87%\n",
      "Batch: 160/391, Loss: 0.6800, Acc: 76.83%\n",
      "Batch: 180/391, Loss: 0.6453, Acc: 76.83%\n",
      "Batch: 200/391, Loss: 0.6908, Acc: 76.92%\n",
      "Batch: 220/391, Loss: 0.5330, Acc: 77.05%\n",
      "Batch: 240/391, Loss: 0.7935, Acc: 77.02%\n",
      "Batch: 260/391, Loss: 0.6952, Acc: 77.04%\n",
      "Batch: 280/391, Loss: 0.6388, Acc: 76.99%\n",
      "Batch: 300/391, Loss: 0.7054, Acc: 77.01%\n",
      "Batch: 320/391, Loss: 0.6049, Acc: 77.02%\n",
      "Batch: 340/391, Loss: 0.6305, Acc: 77.02%\n",
      "Batch: 360/391, Loss: 0.5591, Acc: 77.05%\n",
      "Batch: 380/391, Loss: 0.9117, Acc: 77.07%\n",
      "Epoch Time: 90.48s\n",
      "Train Loss: 0.6872 | Train Acc: 77.10%\n",
      "Test Loss: 0.5270 | Test Acc: 82.49%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 14/30\n",
      "Batch: 20/391, Loss: 0.7277, Acc: 76.29%\n",
      "Batch: 40/391, Loss: 0.4351, Acc: 77.66%\n",
      "Batch: 60/391, Loss: 0.6972, Acc: 77.71%\n",
      "Batch: 80/391, Loss: 0.7007, Acc: 77.84%\n",
      "Batch: 100/391, Loss: 0.7956, Acc: 77.50%\n",
      "Batch: 120/391, Loss: 0.5521, Acc: 77.95%\n",
      "Batch: 140/391, Loss: 0.6126, Acc: 78.04%\n",
      "Batch: 160/391, Loss: 0.6640, Acc: 77.99%\n",
      "Batch: 180/391, Loss: 0.7117, Acc: 78.00%\n",
      "Batch: 200/391, Loss: 0.5911, Acc: 77.96%\n",
      "Batch: 220/391, Loss: 0.6923, Acc: 77.89%\n",
      "Batch: 240/391, Loss: 0.8752, Acc: 77.88%\n",
      "Batch: 260/391, Loss: 0.7152, Acc: 77.80%\n",
      "Batch: 280/391, Loss: 0.6500, Acc: 77.87%\n",
      "Batch: 300/391, Loss: 0.4704, Acc: 78.04%\n",
      "Batch: 320/391, Loss: 0.6336, Acc: 78.08%\n",
      "Batch: 340/391, Loss: 0.7735, Acc: 78.08%\n",
      "Batch: 360/391, Loss: 0.5619, Acc: 78.19%\n",
      "Batch: 380/391, Loss: 0.8118, Acc: 78.19%\n",
      "Epoch Time: 88.38s\n",
      "Train Loss: 0.6594 | Train Acc: 78.22%\n",
      "Test Loss: 0.4963 | Test Acc: 83.51%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 15/30\n",
      "Batch: 20/391, Loss: 0.5791, Acc: 77.54%\n",
      "Batch: 40/391, Loss: 0.6586, Acc: 77.99%\n",
      "Batch: 60/391, Loss: 0.4682, Acc: 78.44%\n",
      "Batch: 80/391, Loss: 0.5978, Acc: 78.37%\n",
      "Batch: 100/391, Loss: 0.6337, Acc: 78.58%\n",
      "Batch: 120/391, Loss: 0.6825, Acc: 78.43%\n",
      "Batch: 140/391, Loss: 0.6004, Acc: 78.56%\n",
      "Batch: 160/391, Loss: 0.6332, Acc: 78.68%\n",
      "Batch: 180/391, Loss: 0.5319, Acc: 78.79%\n",
      "Batch: 200/391, Loss: 0.7926, Acc: 78.59%\n",
      "Batch: 220/391, Loss: 0.7194, Acc: 78.62%\n",
      "Batch: 240/391, Loss: 0.6702, Acc: 78.59%\n",
      "Batch: 260/391, Loss: 0.6733, Acc: 78.69%\n",
      "Batch: 280/391, Loss: 0.6933, Acc: 78.73%\n",
      "Batch: 300/391, Loss: 0.5273, Acc: 78.76%\n",
      "Batch: 320/391, Loss: 0.5838, Acc: 78.80%\n",
      "Batch: 340/391, Loss: 0.6628, Acc: 78.82%\n",
      "Batch: 360/391, Loss: 0.6779, Acc: 78.84%\n",
      "Batch: 380/391, Loss: 0.5911, Acc: 78.87%\n",
      "Epoch Time: 91.25s\n",
      "Train Loss: 0.6333 | Train Acc: 78.85%\n",
      "Test Loss: 0.5020 | Test Acc: 82.84%\n",
      "\n",
      "Epoch: 16/30\n",
      "Batch: 20/391, Loss: 0.5890, Acc: 80.47%\n",
      "Batch: 40/391, Loss: 0.6393, Acc: 79.79%\n",
      "Batch: 60/391, Loss: 0.6349, Acc: 79.57%\n",
      "Batch: 80/391, Loss: 0.7045, Acc: 79.49%\n",
      "Batch: 100/391, Loss: 0.5378, Acc: 79.50%\n",
      "Batch: 120/391, Loss: 0.5578, Acc: 79.55%\n",
      "Batch: 140/391, Loss: 0.7448, Acc: 79.77%\n",
      "Batch: 160/391, Loss: 0.5398, Acc: 79.91%\n",
      "Batch: 180/391, Loss: 0.7591, Acc: 79.91%\n",
      "Batch: 200/391, Loss: 0.8516, Acc: 79.89%\n",
      "Batch: 220/391, Loss: 0.5959, Acc: 79.98%\n",
      "Batch: 240/391, Loss: 0.6399, Acc: 79.86%\n",
      "Batch: 260/391, Loss: 0.6495, Acc: 79.78%\n",
      "Batch: 280/391, Loss: 0.5282, Acc: 79.79%\n",
      "Batch: 300/391, Loss: 0.5807, Acc: 79.81%\n",
      "Batch: 320/391, Loss: 0.5056, Acc: 79.76%\n",
      "Batch: 340/391, Loss: 0.7126, Acc: 79.78%\n",
      "Batch: 360/391, Loss: 0.7086, Acc: 79.81%\n",
      "Batch: 380/391, Loss: 0.5936, Acc: 79.80%\n",
      "Epoch Time: 90.31s\n",
      "Train Loss: 0.6092 | Train Acc: 79.81%\n",
      "Test Loss: 0.4535 | Test Acc: 84.75%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 17/30\n",
      "Batch: 20/391, Loss: 0.5430, Acc: 80.59%\n",
      "Batch: 40/391, Loss: 0.4900, Acc: 80.12%\n",
      "Batch: 60/391, Loss: 0.5934, Acc: 80.39%\n",
      "Batch: 80/391, Loss: 0.5742, Acc: 80.27%\n",
      "Batch: 100/391, Loss: 0.6606, Acc: 80.31%\n",
      "Batch: 120/391, Loss: 0.6497, Acc: 80.39%\n",
      "Batch: 140/391, Loss: 0.4654, Acc: 80.37%\n",
      "Batch: 160/391, Loss: 0.5817, Acc: 80.27%\n",
      "Batch: 180/391, Loss: 0.6575, Acc: 80.24%\n",
      "Batch: 200/391, Loss: 0.6386, Acc: 80.38%\n",
      "Batch: 220/391, Loss: 0.6765, Acc: 80.34%\n",
      "Batch: 240/391, Loss: 0.5131, Acc: 80.45%\n",
      "Batch: 260/391, Loss: 0.4861, Acc: 80.53%\n",
      "Batch: 280/391, Loss: 0.6239, Acc: 80.48%\n",
      "Batch: 300/391, Loss: 0.6422, Acc: 80.39%\n",
      "Batch: 320/391, Loss: 0.5839, Acc: 80.53%\n",
      "Batch: 340/391, Loss: 0.7287, Acc: 80.57%\n",
      "Batch: 360/391, Loss: 0.7384, Acc: 80.53%\n",
      "Batch: 380/391, Loss: 0.5733, Acc: 80.50%\n",
      "Epoch Time: 85.12s\n",
      "Train Loss: 0.5908 | Train Acc: 80.47%\n",
      "Test Loss: 0.4452 | Test Acc: 84.95%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 18/30\n",
      "Batch: 20/391, Loss: 0.6642, Acc: 80.31%\n",
      "Batch: 40/391, Loss: 0.7302, Acc: 80.45%\n",
      "Batch: 60/391, Loss: 0.6132, Acc: 80.62%\n",
      "Batch: 80/391, Loss: 0.3802, Acc: 80.78%\n",
      "Batch: 100/391, Loss: 0.5796, Acc: 80.80%\n",
      "Batch: 120/391, Loss: 0.4257, Acc: 80.70%\n",
      "Batch: 140/391, Loss: 0.5202, Acc: 80.86%\n",
      "Batch: 160/391, Loss: 0.6703, Acc: 80.75%\n",
      "Batch: 180/391, Loss: 0.5513, Acc: 80.83%\n",
      "Batch: 200/391, Loss: 0.5530, Acc: 80.88%\n",
      "Batch: 220/391, Loss: 0.5411, Acc: 80.89%\n",
      "Batch: 240/391, Loss: 0.4564, Acc: 80.94%\n",
      "Batch: 260/391, Loss: 0.6241, Acc: 81.01%\n",
      "Batch: 280/391, Loss: 0.4330, Acc: 81.13%\n",
      "Batch: 300/391, Loss: 0.5569, Acc: 81.07%\n",
      "Batch: 320/391, Loss: 0.5514, Acc: 81.09%\n",
      "Batch: 340/391, Loss: 0.5682, Acc: 81.04%\n",
      "Batch: 360/391, Loss: 0.5532, Acc: 81.02%\n",
      "Batch: 380/391, Loss: 0.5755, Acc: 81.06%\n",
      "Epoch Time: 86.32s\n",
      "Train Loss: 0.5658 | Train Acc: 81.09%\n",
      "Test Loss: 0.4453 | Test Acc: 85.32%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 19/30\n",
      "Batch: 20/391, Loss: 0.4791, Acc: 81.48%\n",
      "Batch: 40/391, Loss: 0.4399, Acc: 81.29%\n",
      "Batch: 60/391, Loss: 0.6174, Acc: 82.03%\n",
      "Batch: 80/391, Loss: 0.6680, Acc: 81.89%\n",
      "Batch: 100/391, Loss: 0.6854, Acc: 81.83%\n",
      "Batch: 120/391, Loss: 0.4544, Acc: 81.73%\n",
      "Batch: 140/391, Loss: 0.6381, Acc: 81.78%\n",
      "Batch: 160/391, Loss: 0.6149, Acc: 81.75%\n",
      "Batch: 180/391, Loss: 0.5177, Acc: 81.81%\n",
      "Batch: 200/391, Loss: 0.4310, Acc: 81.84%\n",
      "Batch: 220/391, Loss: 0.6348, Acc: 81.98%\n",
      "Batch: 240/391, Loss: 0.6241, Acc: 82.03%\n",
      "Batch: 260/391, Loss: 0.4117, Acc: 81.95%\n",
      "Batch: 280/391, Loss: 0.5102, Acc: 81.94%\n",
      "Batch: 300/391, Loss: 0.5919, Acc: 81.93%\n",
      "Batch: 320/391, Loss: 0.5747, Acc: 81.92%\n",
      "Batch: 340/391, Loss: 0.4759, Acc: 81.97%\n",
      "Batch: 360/391, Loss: 0.5239, Acc: 81.89%\n",
      "Batch: 380/391, Loss: 0.6716, Acc: 81.83%\n",
      "Epoch Time: 81.55s\n",
      "Train Loss: 0.5470 | Train Acc: 81.83%\n",
      "Test Loss: 0.4173 | Test Acc: 86.24%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 20/30\n",
      "Batch: 20/391, Loss: 0.5077, Acc: 81.48%\n",
      "Batch: 40/391, Loss: 0.4556, Acc: 82.40%\n",
      "Batch: 60/391, Loss: 0.4791, Acc: 82.29%\n",
      "Batch: 80/391, Loss: 0.6691, Acc: 82.36%\n",
      "Batch: 100/391, Loss: 0.6370, Acc: 82.53%\n",
      "Batch: 120/391, Loss: 0.5303, Acc: 82.51%\n",
      "Batch: 140/391, Loss: 0.5665, Acc: 82.54%\n",
      "Batch: 160/391, Loss: 0.3320, Acc: 82.64%\n",
      "Batch: 180/391, Loss: 0.3782, Acc: 82.64%\n",
      "Batch: 200/391, Loss: 0.5603, Acc: 82.46%\n",
      "Batch: 220/391, Loss: 0.4859, Acc: 82.58%\n",
      "Batch: 240/391, Loss: 0.5236, Acc: 82.54%\n",
      "Batch: 260/391, Loss: 0.4700, Acc: 82.52%\n",
      "Batch: 280/391, Loss: 0.4509, Acc: 82.41%\n",
      "Batch: 300/391, Loss: 0.7650, Acc: 82.34%\n",
      "Batch: 320/391, Loss: 0.5410, Acc: 82.34%\n",
      "Batch: 340/391, Loss: 0.4936, Acc: 82.36%\n",
      "Batch: 360/391, Loss: 0.4905, Acc: 82.34%\n",
      "Batch: 380/391, Loss: 0.6209, Acc: 82.32%\n",
      "Epoch Time: 81.26s\n",
      "Train Loss: 0.5329 | Train Acc: 82.30%\n",
      "Test Loss: 0.4149 | Test Acc: 86.27%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 21/30\n",
      "Batch: 20/391, Loss: 0.4640, Acc: 82.70%\n",
      "Batch: 40/391, Loss: 0.4678, Acc: 83.75%\n",
      "Batch: 60/391, Loss: 0.5339, Acc: 83.49%\n",
      "Batch: 80/391, Loss: 0.5987, Acc: 83.37%\n",
      "Batch: 100/391, Loss: 0.4085, Acc: 83.45%\n",
      "Batch: 120/391, Loss: 0.4214, Acc: 83.58%\n",
      "Batch: 140/391, Loss: 0.4727, Acc: 83.68%\n",
      "Batch: 160/391, Loss: 0.5778, Acc: 83.67%\n",
      "Batch: 180/391, Loss: 0.5290, Acc: 83.53%\n",
      "Batch: 200/391, Loss: 0.4796, Acc: 83.46%\n",
      "Batch: 220/391, Loss: 0.4492, Acc: 83.52%\n",
      "Batch: 240/391, Loss: 0.3860, Acc: 83.49%\n",
      "Batch: 260/391, Loss: 0.5690, Acc: 83.52%\n",
      "Batch: 280/391, Loss: 0.6047, Acc: 83.51%\n",
      "Batch: 300/391, Loss: 0.5113, Acc: 83.31%\n",
      "Batch: 320/391, Loss: 0.4990, Acc: 83.27%\n",
      "Batch: 340/391, Loss: 0.7328, Acc: 83.22%\n",
      "Batch: 360/391, Loss: 0.4988, Acc: 83.18%\n",
      "Batch: 380/391, Loss: 0.5411, Acc: 83.11%\n",
      "Epoch Time: 82.78s\n",
      "Train Loss: 0.5128 | Train Acc: 83.08%\n",
      "Test Loss: 0.3992 | Test Acc: 86.41%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 22/30\n",
      "Batch: 20/391, Loss: 0.5394, Acc: 82.46%\n",
      "Batch: 40/391, Loss: 0.4706, Acc: 83.18%\n",
      "Batch: 60/391, Loss: 0.5383, Acc: 83.39%\n",
      "Batch: 80/391, Loss: 0.7169, Acc: 83.19%\n",
      "Batch: 100/391, Loss: 0.4409, Acc: 82.91%\n",
      "Batch: 120/391, Loss: 0.5233, Acc: 82.76%\n",
      "Batch: 140/391, Loss: 0.4908, Acc: 82.81%\n",
      "Batch: 160/391, Loss: 0.5009, Acc: 82.94%\n",
      "Batch: 180/391, Loss: 0.3421, Acc: 83.05%\n",
      "Batch: 200/391, Loss: 0.5502, Acc: 83.17%\n",
      "Batch: 220/391, Loss: 0.6009, Acc: 83.14%\n",
      "Batch: 240/391, Loss: 0.5007, Acc: 83.20%\n",
      "Batch: 260/391, Loss: 0.6012, Acc: 83.21%\n",
      "Batch: 280/391, Loss: 0.3839, Acc: 83.28%\n",
      "Batch: 300/391, Loss: 0.4820, Acc: 83.33%\n",
      "Batch: 320/391, Loss: 0.4936, Acc: 83.22%\n",
      "Batch: 340/391, Loss: 0.4623, Acc: 83.22%\n",
      "Batch: 360/391, Loss: 0.5832, Acc: 83.24%\n",
      "Batch: 380/391, Loss: 0.4489, Acc: 83.20%\n",
      "Epoch Time: 81.56s\n",
      "Train Loss: 0.5046 | Train Acc: 83.23%\n",
      "Test Loss: 0.3964 | Test Acc: 87.12%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 23/30\n",
      "Batch: 20/391, Loss: 0.5089, Acc: 83.55%\n",
      "Batch: 40/391, Loss: 0.3471, Acc: 83.14%\n",
      "Batch: 60/391, Loss: 0.7926, Acc: 83.42%\n",
      "Batch: 80/391, Loss: 0.5592, Acc: 83.23%\n",
      "Batch: 100/391, Loss: 0.4082, Acc: 83.44%\n",
      "Batch: 120/391, Loss: 0.6571, Acc: 83.51%\n",
      "Batch: 140/391, Loss: 0.5598, Acc: 83.64%\n",
      "Batch: 160/391, Loss: 0.4748, Acc: 83.71%\n",
      "Batch: 180/391, Loss: 0.4987, Acc: 83.65%\n",
      "Batch: 200/391, Loss: 0.6027, Acc: 83.71%\n",
      "Batch: 220/391, Loss: 0.4275, Acc: 83.67%\n",
      "Batch: 240/391, Loss: 0.5672, Acc: 83.64%\n",
      "Batch: 260/391, Loss: 0.4531, Acc: 83.63%\n",
      "Batch: 280/391, Loss: 0.4071, Acc: 83.59%\n",
      "Batch: 300/391, Loss: 0.4847, Acc: 83.63%\n",
      "Batch: 320/391, Loss: 0.4914, Acc: 83.56%\n",
      "Batch: 340/391, Loss: 0.5032, Acc: 83.60%\n",
      "Batch: 360/391, Loss: 0.4338, Acc: 83.62%\n",
      "Batch: 380/391, Loss: 0.5094, Acc: 83.60%\n",
      "Epoch Time: 82.67s\n",
      "Train Loss: 0.4866 | Train Acc: 83.61%\n",
      "Test Loss: 0.3946 | Test Acc: 86.96%\n",
      "\n",
      "Epoch: 24/30\n",
      "Batch: 20/391, Loss: 0.5947, Acc: 85.16%\n",
      "Batch: 40/391, Loss: 0.5430, Acc: 84.53%\n",
      "Batch: 60/391, Loss: 0.3977, Acc: 84.64%\n",
      "Batch: 80/391, Loss: 0.5318, Acc: 84.30%\n",
      "Batch: 100/391, Loss: 0.4498, Acc: 84.02%\n",
      "Batch: 120/391, Loss: 0.4328, Acc: 83.99%\n",
      "Batch: 140/391, Loss: 0.5473, Acc: 84.07%\n",
      "Batch: 160/391, Loss: 0.5920, Acc: 84.09%\n",
      "Batch: 180/391, Loss: 0.6195, Acc: 84.09%\n",
      "Batch: 200/391, Loss: 0.4937, Acc: 84.11%\n",
      "Batch: 220/391, Loss: 0.4577, Acc: 84.03%\n",
      "Batch: 240/391, Loss: 0.5207, Acc: 84.04%\n",
      "Batch: 260/391, Loss: 0.4487, Acc: 84.10%\n",
      "Batch: 280/391, Loss: 0.3598, Acc: 84.11%\n",
      "Batch: 300/391, Loss: 0.6399, Acc: 84.04%\n",
      "Batch: 320/391, Loss: 0.4830, Acc: 84.09%\n",
      "Batch: 340/391, Loss: 0.5702, Acc: 84.06%\n",
      "Batch: 360/391, Loss: 0.6406, Acc: 83.99%\n",
      "Batch: 380/391, Loss: 0.4363, Acc: 83.97%\n",
      "Epoch Time: 89.66s\n",
      "Train Loss: 0.4783 | Train Acc: 83.93%\n",
      "Test Loss: 0.4268 | Test Acc: 85.94%\n",
      "\n",
      "Epoch: 25/30\n",
      "Batch: 20/391, Loss: 0.3066, Acc: 85.66%\n",
      "Batch: 40/391, Loss: 0.5637, Acc: 85.27%\n",
      "Batch: 60/391, Loss: 0.6479, Acc: 84.83%\n",
      "Batch: 80/391, Loss: 0.4736, Acc: 84.67%\n",
      "Batch: 100/391, Loss: 0.6322, Acc: 84.56%\n",
      "Batch: 120/391, Loss: 0.5100, Acc: 84.36%\n",
      "Batch: 140/391, Loss: 0.5023, Acc: 84.51%\n",
      "Batch: 160/391, Loss: 0.3957, Acc: 84.42%\n",
      "Batch: 180/391, Loss: 0.4287, Acc: 84.47%\n",
      "Batch: 200/391, Loss: 0.5034, Acc: 84.44%\n",
      "Batch: 220/391, Loss: 0.4693, Acc: 84.41%\n",
      "Batch: 240/391, Loss: 0.4568, Acc: 84.41%\n",
      "Batch: 260/391, Loss: 0.4971, Acc: 84.39%\n",
      "Batch: 280/391, Loss: 0.4745, Acc: 84.34%\n",
      "Batch: 300/391, Loss: 0.4627, Acc: 84.35%\n",
      "Batch: 320/391, Loss: 0.4917, Acc: 84.30%\n",
      "Batch: 340/391, Loss: 0.3190, Acc: 84.27%\n",
      "Batch: 360/391, Loss: 0.6744, Acc: 84.30%\n",
      "Batch: 380/391, Loss: 0.5106, Acc: 84.34%\n",
      "Epoch Time: 93.46s\n",
      "Train Loss: 0.4688 | Train Acc: 84.33%\n",
      "Test Loss: 0.3763 | Test Acc: 87.62%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 26/30\n",
      "Batch: 20/391, Loss: 0.4373, Acc: 84.77%\n",
      "Batch: 40/391, Loss: 0.4853, Acc: 85.27%\n",
      "Batch: 60/391, Loss: 0.4120, Acc: 85.38%\n",
      "Batch: 80/391, Loss: 0.4645, Acc: 85.56%\n",
      "Batch: 100/391, Loss: 0.3424, Acc: 85.64%\n",
      "Batch: 120/391, Loss: 0.4130, Acc: 85.59%\n",
      "Batch: 140/391, Loss: 0.4091, Acc: 85.52%\n",
      "Batch: 160/391, Loss: 0.5586, Acc: 85.55%\n",
      "Batch: 180/391, Loss: 0.5567, Acc: 85.35%\n",
      "Batch: 200/391, Loss: 0.5336, Acc: 85.20%\n",
      "Batch: 220/391, Loss: 0.2980, Acc: 85.16%\n",
      "Batch: 240/391, Loss: 0.4549, Acc: 85.11%\n",
      "Batch: 260/391, Loss: 0.5072, Acc: 85.06%\n",
      "Batch: 280/391, Loss: 0.4047, Acc: 85.10%\n",
      "Batch: 300/391, Loss: 0.3891, Acc: 85.10%\n",
      "Batch: 320/391, Loss: 0.4239, Acc: 85.03%\n",
      "Batch: 340/391, Loss: 0.5306, Acc: 84.99%\n",
      "Batch: 360/391, Loss: 0.3834, Acc: 84.97%\n",
      "Batch: 380/391, Loss: 0.4461, Acc: 84.96%\n",
      "Epoch Time: 91.02s\n",
      "Train Loss: 0.4536 | Train Acc: 84.96%\n",
      "Test Loss: 0.3733 | Test Acc: 87.72%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 27/30\n",
      "Batch: 20/391, Loss: 0.3936, Acc: 84.73%\n",
      "Batch: 40/391, Loss: 0.2997, Acc: 85.08%\n",
      "Batch: 60/391, Loss: 0.4680, Acc: 85.95%\n",
      "Batch: 80/391, Loss: 0.4497, Acc: 85.63%\n",
      "Batch: 100/391, Loss: 0.6215, Acc: 85.41%\n",
      "Batch: 120/391, Loss: 0.3806, Acc: 85.23%\n",
      "Batch: 140/391, Loss: 0.5151, Acc: 85.19%\n",
      "Batch: 160/391, Loss: 0.5994, Acc: 85.10%\n",
      "Batch: 180/391, Loss: 0.4996, Acc: 85.12%\n",
      "Batch: 200/391, Loss: 0.4128, Acc: 85.19%\n",
      "Batch: 220/391, Loss: 0.4303, Acc: 85.13%\n",
      "Batch: 240/391, Loss: 0.5800, Acc: 85.09%\n",
      "Batch: 260/391, Loss: 0.4821, Acc: 85.05%\n",
      "Batch: 280/391, Loss: 0.4758, Acc: 84.97%\n",
      "Batch: 300/391, Loss: 0.4859, Acc: 84.92%\n",
      "Batch: 320/391, Loss: 0.3116, Acc: 84.99%\n",
      "Batch: 340/391, Loss: 0.3211, Acc: 85.01%\n",
      "Batch: 360/391, Loss: 0.5498, Acc: 84.94%\n",
      "Batch: 380/391, Loss: 0.4786, Acc: 84.97%\n",
      "Epoch Time: 84.17s\n",
      "Train Loss: 0.4461 | Train Acc: 84.99%\n",
      "Test Loss: 0.3906 | Test Acc: 87.28%\n",
      "\n",
      "Epoch: 28/30\n",
      "Batch: 20/391, Loss: 0.4060, Acc: 86.37%\n",
      "Batch: 40/391, Loss: 0.3736, Acc: 85.94%\n",
      "Batch: 60/391, Loss: 0.5310, Acc: 85.60%\n",
      "Batch: 80/391, Loss: 0.3862, Acc: 85.69%\n",
      "Batch: 100/391, Loss: 0.5001, Acc: 85.98%\n",
      "Batch: 120/391, Loss: 0.3932, Acc: 85.75%\n",
      "Batch: 140/391, Loss: 0.3977, Acc: 85.54%\n",
      "Batch: 160/391, Loss: 0.4297, Acc: 85.50%\n",
      "Batch: 180/391, Loss: 0.3972, Acc: 85.45%\n",
      "Batch: 200/391, Loss: 0.4269, Acc: 85.38%\n",
      "Batch: 220/391, Loss: 0.4816, Acc: 85.32%\n",
      "Batch: 240/391, Loss: 0.4484, Acc: 85.30%\n",
      "Batch: 260/391, Loss: 0.5569, Acc: 85.36%\n",
      "Batch: 280/391, Loss: 0.3902, Acc: 85.38%\n",
      "Batch: 300/391, Loss: 0.2815, Acc: 85.36%\n",
      "Batch: 320/391, Loss: 0.4594, Acc: 85.33%\n",
      "Batch: 340/391, Loss: 0.6211, Acc: 85.31%\n",
      "Batch: 360/391, Loss: 0.5768, Acc: 85.26%\n",
      "Batch: 380/391, Loss: 0.5849, Acc: 85.21%\n",
      "Epoch Time: 82.83s\n",
      "Train Loss: 0.4378 | Train Acc: 85.24%\n",
      "Test Loss: 0.3666 | Test Acc: 87.85%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 29/30\n",
      "Batch: 20/391, Loss: 0.4236, Acc: 85.59%\n",
      "Batch: 40/391, Loss: 0.5047, Acc: 85.45%\n",
      "Batch: 60/391, Loss: 0.4401, Acc: 85.47%\n",
      "Batch: 80/391, Loss: 0.4390, Acc: 85.39%\n",
      "Batch: 100/391, Loss: 0.5005, Acc: 85.38%\n",
      "Batch: 120/391, Loss: 0.3432, Acc: 85.36%\n",
      "Batch: 140/391, Loss: 0.5172, Acc: 85.31%\n",
      "Batch: 160/391, Loss: 0.4163, Acc: 85.28%\n",
      "Batch: 180/391, Loss: 0.3713, Acc: 85.30%\n",
      "Batch: 200/391, Loss: 0.4106, Acc: 85.40%\n",
      "Batch: 220/391, Loss: 0.3027, Acc: 85.52%\n",
      "Batch: 240/391, Loss: 0.4055, Acc: 85.51%\n",
      "Batch: 260/391, Loss: 0.4063, Acc: 85.54%\n",
      "Batch: 280/391, Loss: 0.5082, Acc: 85.42%\n",
      "Batch: 300/391, Loss: 0.2894, Acc: 85.41%\n",
      "Batch: 320/391, Loss: 0.4798, Acc: 85.37%\n",
      "Batch: 340/391, Loss: 0.3785, Acc: 85.37%\n",
      "Batch: 360/391, Loss: 0.4579, Acc: 85.41%\n",
      "Batch: 380/391, Loss: 0.4941, Acc: 85.38%\n",
      "Epoch Time: 82.68s\n",
      "Train Loss: 0.4315 | Train Acc: 85.38%\n",
      "Test Loss: 0.3666 | Test Acc: 88.29%\n",
      "Saving model...\n",
      "\n",
      "Epoch: 30/30\n",
      "Batch: 20/391, Loss: 0.4241, Acc: 85.08%\n",
      "Batch: 40/391, Loss: 0.3830, Acc: 85.94%\n",
      "Batch: 60/391, Loss: 0.5205, Acc: 85.60%\n",
      "Batch: 80/391, Loss: 0.2562, Acc: 85.72%\n",
      "Batch: 100/391, Loss: 0.6293, Acc: 85.55%\n",
      "Batch: 120/391, Loss: 0.4283, Acc: 85.50%\n",
      "Batch: 140/391, Loss: 0.4117, Acc: 85.43%\n",
      "Batch: 160/391, Loss: 0.3907, Acc: 85.39%\n",
      "Batch: 180/391, Loss: 0.3897, Acc: 85.56%\n",
      "Batch: 200/391, Loss: 0.4670, Acc: 85.63%\n",
      "Batch: 220/391, Loss: 0.4267, Acc: 85.68%\n",
      "Batch: 240/391, Loss: 0.5186, Acc: 85.67%\n",
      "Batch: 260/391, Loss: 0.3109, Acc: 85.64%\n",
      "Batch: 280/391, Loss: 0.3504, Acc: 85.69%\n",
      "Batch: 300/391, Loss: 0.4914, Acc: 85.68%\n",
      "Batch: 320/391, Loss: 0.3077, Acc: 85.71%\n",
      "Batch: 340/391, Loss: 0.6270, Acc: 85.70%\n",
      "Batch: 360/391, Loss: 0.4860, Acc: 85.69%\n",
      "Batch: 380/391, Loss: 0.4266, Acc: 85.74%\n",
      "Epoch Time: 83.73s\n",
      "Train Loss: 0.4276 | Train Acc: 85.73%\n",
      "Test Loss: 0.3537 | Test Acc: 88.47%\n",
      "Saving model...\n",
      "\n",
      "Best accuracy: 88.47%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 設定設備並檢查 MPS 可用性\n",
    "device = (\n",
    "    \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = torch.device(device)\n",
    "print(f'使用設備: {device}')\n",
    "\n",
    "# 數據預處理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# 載入CIFAR-10數據集\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                             download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transform_test)\n",
    "\n",
    "# 針對 M1/M2 優化的數據加載器配置\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, \n",
    "                        num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, \n",
    "                        num_workers=2, pin_memory=True)\n",
    "\n",
    "# 定義改進版CNN模型\n",
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 將模型移至設備\n",
    "model = DeepCNN().to(device)\n",
    "\n",
    "# 優化器設定\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# 訓練函數\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad(True)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if (batch_idx + 1) % 20 == 0:\n",
    "            print(f'Batch: {batch_idx + 1}/{len(loader)}, Loss: {loss.item():.4f}, '\n",
    "                  f'Acc: {100.*correct/total:.2f}%')\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# 訓練模型\n",
    "num_epochs = 30\n",
    "best_acc = 0\n",
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    print(f'\\nEpoch: {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    \n",
    "    # 評估模型\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    test_acc = 100. * correct / total\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    print(f'Epoch Time: {epoch_time:.2f}s')\n",
    "    print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%')\n",
    "    \n",
    "    if test_acc > best_acc:\n",
    "        print('Saving model...')\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        best_acc = test_acc\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "print(f'\\nBest accuracy: {best_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [10, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Add text showing accuracy on test data\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Use the SimpleNet model for binary classification\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     test_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     _, test_predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(test_outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m     true_labels \u001b[38;5;241m=\u001b[39m (test_X[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m test_X[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 83\u001b[0m, in \u001b[0;36mDeepCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 83\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     85\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [10, 2]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure we're using the SimpleNet model from cell 0\n",
    "# Create scatter plot of the data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot points for class 0 and class 1 separately\n",
    "plt.scatter(X[y==0, 0].numpy(), X[y==0, 1].numpy(), c='red', label='Class 0', alpha=0.6)\n",
    "plt.scatter(X[y==1, 0].numpy(), X[y==1, 1].numpy(), c='blue', label='Class 1', alpha=0.6)\n",
    "\n",
    "# Add decision boundary line (y = -x since points are classified based on x + y > 0)\n",
    "plt.axline([0, 0], [1, -1], color='green', linestyle='--', label='Decision Boundary')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Binary Classification Data Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add text showing accuracy on test data\n",
    "with torch.no_grad():\n",
    "    # Use the SimpleNet model for binary classification\n",
    "    test_outputs = model(test_X)\n",
    "    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    true_labels = (test_X[:, 0] + test_X[:, 1] > 0).long()\n",
    "    accuracy = (test_predicted == true_labels).float().mean()\n",
    "    plt.text(0.02, 0.98, f'Test Accuracy: {accuracy:.2%}', \n",
    "             transform=plt.gca().transAxes, \n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
